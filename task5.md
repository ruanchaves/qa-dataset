Anthropic just published an interesting blog post on measuring political bias in AI models. I think this would be relevant for our research discussions. 

They've developed a framework for evaluating how models handle political content across different ideologies, which could inform our own bias assessment work. Worth a read: [link to article]. 

Curious to hear everyone's thoughts on how their methodology compares to approaches we've been exploring.